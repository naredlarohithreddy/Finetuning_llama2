# Finetuning_llama2
This repository contains the setup, configuration, and training code for fine-tuning the Meta LLaMA 2 model using:  Parameter-Efficient Fine-Tuning (PEFT) with LoRA  bitsandbytes for 4-bit quantization
